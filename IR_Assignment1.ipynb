{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "inputPath = \"Input\"\n",
    "outputPath = \"Output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizatiion of Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open((os.path.join(\"twitter_data.txt\")), mode='r', encoding=\"Latin-1\")\n",
    "\n",
    "twitter_data = input_file.read()\n",
    "input_file.close()\n",
    "\n",
    "twitter_tokens = word_tokenize(twitter_data )\n",
    "\n",
    "twitter_tokens_output_file = open((os.path.join(outputPath,\"twitter_data_tokens.txt\")), mode='w+',encoding=\"Latin-1\")\n",
    "\n",
    "\n",
    "for token in twitter_tokens:\n",
    "    twitter_tokens_output_file.write(token + \"\\n\")\n",
    "    \n",
    "twitter_tokens_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizatiion of Student feedback data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open((os.path.join(inputPath, \"Student_Course_Feedback.txt\")), mode='r', encoding=\"utf-8\")\n",
    "\n",
    "student_feedback = input_file.read()\n",
    "input_file.close()\n",
    "\n",
    "student_feedback_tokens = word_tokenize(student_feedback)\n",
    "\n",
    "studentfeedback_tokens_output_file = open((os.path.join(outputPath,\"student_feedback_tokens.txt\")), mode='w+', encoding=\"utf-8\")\n",
    "\n",
    "for token in student_feedback_tokens:\n",
    "    studentfeedback_tokens_output_file.write(token + \"\\n\")\n",
    "    \n",
    "studentfeedback_tokens_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizatiion of Research paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open((os.path.join(inputPath, \"research_paper.txt\")), mode='r', encoding=\"utf-8\")\n",
    "\n",
    "research_paper = input_file.read()\n",
    "input_file.close()\n",
    "\n",
    "research_paper_tokens = word_tokenize(research_paper)\n",
    "\n",
    "research_paper_tokens_output_file = open((os.path.join(outputPath,\"research_paper_tokens.txt\")),mode='w+', encoding=\"utf-8\")\n",
    "\n",
    "for token in research_paper_tokens:\n",
    "    research_paper_tokens_output_file.write(token + \"\\n\")\n",
    "    \n",
    "research_paper_tokens_output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Correction - Isolated Word Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolated word correction for twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter misspelled tokens count =  87\n"
     ]
    }
   ],
   "source": [
    "spell = SpellChecker()\n",
    "twitter_misspelled_tokens = spell.unknown(twitter_tokens)\n",
    "\n",
    "print(\"Twitter misspelled tokens count = \", len(twitter_misspelled_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_misspelled_output_file = open((os.path.join(outputPath,'twitter_isolated_correction_tokens.csv')), mode='w+', encoding=\"Latin-1\")\n",
    "twitter_misspelled_output_file.write(\"Misspelled Token,Corrected Token\\n\")\n",
    "\n",
    "for token in twitter_misspelled_tokens:\n",
    "    twitter_misspelled_output_file.write(token + \",\")\n",
    "    twitter_misspelled_output_file.write(spell.correction(token) + \"\\n\")\n",
    "\n",
    "twitter_misspelled_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolated word correction for Student feedback data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student feedback misspelled tokens count =  14\n"
     ]
    }
   ],
   "source": [
    "student_feedback_misspelled_tokens = spell.unknown(student_feedback_tokens)\n",
    "\n",
    "print(\"Student feedback misspelled tokens count = \", len(student_feedback_misspelled_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_misspelled_output_file = open((os.path.join(outputPath,'student_feedback_isolated_correction_tokens.csv')), mode='w+', encoding=\"utf-8\")\n",
    "student_misspelled_output_file.write(\"Missplled Token,Corrected Token\\n\")\n",
    "\n",
    "for token in student_feedback_misspelled_tokens:\n",
    "    student_misspelled_output_file.write(token + \",\")\n",
    "    student_misspelled_output_file.write(spell.correction(token) + \"\\n\")\n",
    "\n",
    "student_misspelled_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolated word correction for research Paper data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Paper misspelled tokens count =  16\n"
     ]
    }
   ],
   "source": [
    "research_paper_misspelled_tokens = spell.unknown(research_paper_tokens)\n",
    "\n",
    "print(\"Research Paper misspelled tokens count = \", len(research_paper_misspelled_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "researhpaper_misspelled_output_file = open((os.path.join(outputPath,'researchpaper_isolated_correction_tokens.csv')), mode='w+',encoding=\"utf-8\")\n",
    "researhpaper_misspelled_output_file.write(\"Misspelled Token,Corrected Token\\n\")\n",
    "\n",
    "for token in research_paper_misspelled_tokens:\n",
    "    researhpaper_misspelled_output_file.write(token + \",\")\n",
    "    researhpaper_misspelled_output_file.write(spell.correction(token) + \"\\n\")\n",
    "\n",
    "researhpaper_misspelled_output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Correction - Context sensitive word correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy.symspellpy import SymSpell, Verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edit_distance_dictionary = 2\n",
    "prefix_length = 7\n",
    "\n",
    "sym_spell = SymSpell(max_edit_distance_dictionary, prefix_length)\n",
    "\n",
    "# create dictionary using big.txt\n",
    "if not sym_spell.create_dictionary(\"big.txt\"):\n",
    "    print(\"Corpus file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Context sensitive word correction for twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Biwords >> Reminds me\n",
      "Correct Biwords >> me of\n",
      "Correct Biwords >> of Liberal\n",
      "Correct Biwords >> Liberal Immigration\n",
      "Correct Biwords >> from Canada\n",
      "Correct Biwords >> We want\n",
      "Correct Biwords >> want controlled\n",
      "Correct Biwords >> controlled immigration\n",
      "Correct Biwords >> immigration that\n",
      "Correct Biwords >> that contributes\n",
      "Correct Biwords >> contributes positively\n",
      "Correct Biwords >> positively to\n",
      "Correct Biwords >> to the\n",
      "Correct Biwords >> Same as\n",
      "Correct Biwords >> as Australia\n",
      "Correct Biwords >> Is the\n",
      "Correct Biwords >> the new\n",
      "Correct Biwords >> immigration fee\n",
      "Correct Biwords >> fee a\n",
      "Correct Biwords >> a head\n",
      "Correct Biwords >> head tax\n",
      "Correct Biwords >> Canada immigration\n",
      "Correct Biwords >> immigration profit\n",
      "Correct Biwords >> profit influence\n",
      "Correct Biwords >> delhi yet\n",
      "Correct Biwords >> Canada Immigration\n",
      "Correct Biwords >> Immigration Minister\n",
      "Correct Biwords >> Minister to\n",
      "Correct Biwords >> Increase Immigration\n",
      "Correct Biwords >> Immigration Numbers\n",
      "Correct Biwords >> par excellence\n",
      "Correct Biwords >> what changes\n",
      "Correct Biwords >> changes should\n",
      "Correct Biwords >> should be\n",
      "Correct Biwords >> be made\n",
      "Correct Biwords >> made to\n",
      "Correct Biwords >> to Canada\n",
      "Correct Biwords >> 's immigration\n",
      "Correct Biwords >> immigration laws\n",
      "Correct Biwords >> laws due\n",
      "Correct Biwords >> due to\n",
      "Correct Biwords >> to the\n",
      "Correct Biwords >> the influx\n",
      "Correct Biwords >> influx of\n",
      "Correct Biwords >> of immigration\n",
      "Correct Biwords >> immigration and\n",
      "Correct Biwords >> and violence\n",
      "Correct Biwords >> au Canada\n",
      "Correct Biwords >> en 5\n",
      "Correct Biwords >> 5 questions\n",
      "Correct Biwords >> au Canada\n",
      "Correct Biwords >> en 5\n",
      "Correct Biwords >> 5 questions\n",
      "Correct Biwords >> Will Media\n",
      "Correct Biwords >> Media ask\n",
      "Correct Biwords >> ask the\n",
      "Correct Biwords >> the Liberals\n",
      "Correct Biwords >> Liberals if\n",
      "Correct Biwords >> if they\n",
      "Correct Biwords >> they actually\n",
      "Correct Biwords >> actually have\n",
      "Correct Biwords >> have a\n",
      "Correct Biwords >> a solid\n",
      "Correct Biwords >> solid plan\n",
      "Correct Biwords >> plan for\n",
      "Correct Biwords >> for Canada\n",
      "Correct Biwords >> From my\n",
      "Correct Biwords >> my view\n",
      "Correct Biwords >> immigration out\n",
      "Correct Biwords >> out of\n",
      "Correct Biwords >> Dan Murray\n",
      "Correct Biwords >> Watch Canada\n",
      "Correct Biwords >> Canada is\n",
      "Correct Biwords >> Le Canada\n",
      "Correct Biwords >> Canada lance\n",
      "Correct Biwords >> lance une\n",
      "Correct Biwords >> pour faire\n",
      "Correct Biwords >> faire face\n",
      "Correct Biwords >> de main\n",
      "Correct Biwords >> main d\n",
      "Correct Biwords >> read the\n",
      "Correct Biwords >> the Immigration\n",
      "Correct Biwords >> Immigration laws\n",
      "Correct Biwords >> laws of\n",
      "Correct Biwords >> of Canada\n",
      "Correct Biwords >> Canada much\n",
      "Correct Biwords >> much stricter\n",
      "Correct Biwords >> stricter than\n",
      "Correct Biwords >> than the\n",
      "Correct Biwords >> the US\n",
      "Correct Biwords >> US Canada\n",
      "Correct Biwords >> Canada Immigration\n",
      "Correct Biwords >> In Wake\n",
      "Correct Biwords >> Wake Of\n",
      "Correct Biwords >> of Canada\n",
      "Correct Biwords >> Canada Immigration\n",
      "Correct Biwords >> Move to\n",
      "Correct Biwords >> to Canada\n",
      "Correct Biwords >> immigration rules\n",
      "Correct Biwords >> you ca\n",
      "Correct Biwords >> becomes Canada\n",
      "Correct Biwords >> 's 2\n",
      "Correct Biwords >> 2 millionth\n",
      "Correct Biwords >> millionth immigrant\n",
      "Correct Biwords >> immigrant since\n",
      "Correct Biwords >> Do you\n",
      "Correct Biwords >> you know\n",
      "Correct Biwords >> know your\n",
      "Correct Biwords >> your family\n",
      "Correct Biwords >> 's immigration\n",
      "Correct Biwords >> 's open\n",
      "Correct Biwords >> open immigration\n",
      "Correct Biwords >> immigration policies\n",
      "Correct Biwords >> how they\n",
      "Correct Biwords >> they contribute\n",
      "Correct Biwords >> contribute to\n",
      "Correct Biwords >> to our\n",
      "Correct Biwords >> our economic\n",
      "Correct Biwords >> economic success\n",
      "Correct Biwords >> Hundreds may\n",
      "Correct Biwords >> may lose\n",
      "Correct Biwords >> lose Canadian\n",
      "Correct Biwords >> Canadian citizenship\n",
      "Correct Biwords >> resident status\n",
      "Correct Biwords >> status because\n",
      "Correct Biwords >> because of\n",
      "Correct Biwords >> of one\n",
      "Correct Biwords >> one corrupt\n",
      "Correct Biwords >> corrupt immigration\n",
      "Correct Biwords >> immigration consultant\n",
      "Correct Biwords >> Immigration for\n",
      "Correct Biwords >> for canada\n",
      "Correct Biwords >> canada without\n",
      "Correct Biwords >> without india\n",
      "Correct Biwords >> an compassionate\n",
      "Correct Biwords >> compassionate handle\n",
      "Correct Biwords >> lift expected\n",
      "Correct Biwords >> expected to\n",
      "Correct Biwords >> to cost\n",
      "Correct Biwords >> cost Canada\n",
      "Correct Biwords >> over a\n",
      "Correct Biwords >> a decade\n",
      "Correct Biwords >> Are people\n",
      "Correct Biwords >> people still\n",
      "Correct Biwords >> still moving\n",
      "Correct Biwords >> moving to\n",
      "Correct Biwords >> Oh that\n",
      "Correct Biwords >> 's right\n",
      "Correct Biwords >> they have\n",
      "Correct Biwords >> have real\n",
      "Correct Biwords >> real immigration\n",
      "Correct Biwords >> immigration laws\n",
      "Correct Biwords >> laws and\n",
      "Correct Biwords >> Here are\n",
      "Correct Biwords >> are more\n",
      "Correct Biwords >> more details\n",
      "Correct Biwords >> details on\n",
      "Correct Biwords >> on the\n",
      "Correct Biwords >> the Richmond\n",
      "Correct Biwords >> Immigration Consultant\n",
      "Correct Biwords >> Consultant Sunny\n",
      "Correct Biwords >> who was\n",
      "Correct Biwords >> was sentenced\n",
      "Correct Biwords >> sentenced to\n",
      "Correct Biwords >> to 7\n",
      "Correct Biwords >> 7 years\n",
      "Correct Biwords >> years in\n",
      "Correct Biwords >> in ...\n",
      "Correct Biwords >> I added\n",
      "Correct Biwords >> added a\n",
      "Correct Biwords >> a video\n",
      "Correct Biwords >> video to\n",
      "Correct Biwords >> to a\n",
      "Correct Biwords >> Funny Talking\n",
      "Correct Biwords >> Talking of\n",
      "Correct Biwords >> with Canada\n",
      "Correct Biwords >> Canada Immigration\n",
      "Correct Biwords >> Immigration Girl\n",
      "Correct Biwords >> Girl Agent\n",
      "Correct Biwords >> Agent Mexicans\n",
      "Correct Biwords >> Mexicans Can\n",
      "Correct Biwords >> Can Now\n",
      "Correct Biwords >> Now Travel\n",
      "Correct Biwords >> To Canada\n",
      "Correct Biwords >> au Canada\n",
      "Correct Biwords >> up immigration\n",
      "Correct Biwords >> immigration for\n",
      "Correct Biwords >> for Canada\n",
      "Correct Biwords >> among other\n",
      "Correct Biwords >> Canada lifted\n",
      "Correct Biwords >> requirements to\n",
      "Correct Biwords >> to Mexico\n",
      "Correct Biwords >> Mexico as\n",
      "Correct Biwords >> as of\n",
      "Correct Biwords >> of Dec\n",
      "Correct Biwords >> Dec 1\n",
      "Correct Biwords >> people Keep\n",
      "Correct Biwords >> Keep praising\n",
      "Correct Biwords >> praising Canada\n",
      "Correct Biwords >> Canada and\n",
      "Correct Biwords >> and Canada\n",
      "Correct Biwords >> Canada has\n",
      "Correct Biwords >> has way\n",
      "Correct Biwords >> way stricter\n",
      "Correct Biwords >> stricter immigration\n",
      "Correct Biwords >> immigration laws\n",
      "Correct Biwords >> laws then\n",
      "Correct Biwords >> then us\n",
      "Correct Biwords >> us they\n",
      "Correct Biwords >> boot your\n",
      "Correct Biwords >> your liberal\n",
      "Correct Biwords >> liberal American\n",
      "Correct Biwords >> American ass\n"
     ]
    }
   ],
   "source": [
    "twitter_con_sens_corr_output_file = open((os.path.join(outputPath,'twitter_context_sensitive_corrections.csv')), mode='w+', encoding=\"utf-8\")\n",
    "twitter_con_sens_corr_output_file.write(\"Incorrect Biword,\" + \"Corrected Result,\" + \"Edit Distance Sum\" + \"\\n\")\n",
    "\n",
    "for index in range(len(twitter_tokens) - 1):\n",
    "    biword = twitter_tokens[index] + \" \"  + twitter_tokens[index+1]\n",
    "    result = sym_spell.word_segmentation(biword)\n",
    "    \n",
    "    if result.corrected_string.lower() != biword.lower():\n",
    "        twitter_con_sens_corr_output_file.write(biword + \",\" + result.corrected_string + \",\" + str(result.distance_sum) + \"\\n\")\n",
    "    else:\n",
    "        print(\"Correct Biwords >>\", biword)\n",
    "        \n",
    "twitter_con_sens_corr_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Context sensitive word correction for student feedback data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Biwords >> Honestly last\n",
      "Correct Biwords >> last seven\n",
      "Correct Biwords >> seven lectures\n",
      "Correct Biwords >> lectures are\n",
      "Correct Biwords >> are good\n",
      "Correct Biwords >> Lectures are\n",
      "Correct Biwords >> are understandable\n",
      "Correct Biwords >> are very\n",
      "Correct Biwords >> very useful\n",
      "Correct Biwords >> useful to\n",
      "Correct Biwords >> The given\n",
      "Correct Biwords >> given opportunity\n",
      "Correct Biwords >> opportunity to\n",
      "Correct Biwords >> to ask\n",
      "Correct Biwords >> ask questions\n",
      "Correct Biwords >> questions from\n",
      "Correct Biwords >> from the\n",
      "Correct Biwords >> the lecturer\n",
      "Correct Biwords >> lecturer is\n",
      "Correct Biwords >> is appreciative\n",
      "Correct Biwords >> please do\n",
      "Correct Biwords >> at class\n",
      "Correct Biwords >> class starting\n",
      "Correct Biwords >> starting it\n",
      "Correct Biwords >> s better\n",
      "Correct Biwords >> better for\n",
      "Correct Biwords >> for us\n",
      "Correct Biwords >> sometimes teaching\n",
      "Correct Biwords >> teaching speed\n",
      "Correct Biwords >> speed is\n",
      "Correct Biwords >> is very\n",
      "Correct Biwords >> very high\n",
      "Correct Biwords >> The lectures\n",
      "Correct Biwords >> lectures are\n",
      "Correct Biwords >> a bit\n",
      "Correct Biwords >> in class\n",
      "Correct Biwords >> class working\n",
      "Correct Biwords >> working activity\n",
      "Correct Biwords >> activity is\n",
      "Correct Biwords >> is a\n",
      "Correct Biwords >> a must\n",
      "Correct Biwords >> please take\n",
      "Correct Biwords >> take another\n",
      "Correct Biwords >> another hour\n",
      "Correct Biwords >> hour in\n",
      "Correct Biwords >> in thursdays\n",
      "Correct Biwords >> We can\n",
      "Correct Biwords >> can hear\n",
      "Correct Biwords >> hear your\n",
      "Correct Biwords >> your voice\n",
      "Correct Biwords >> voice clearly\n",
      "Correct Biwords >> clearly and\n",
      "Correct Biwords >> and can\n",
      "Correct Biwords >> can understand\n",
      "Correct Biwords >> understand the\n",
      "Correct Biwords >> the things\n",
      "Correct Biwords >> things you\n",
      "Correct Biwords >> you teach\n",
      "Correct Biwords >> also good\n",
      "Correct Biwords >> good source\n",
      "Correct Biwords >> source to\n",
      "Correct Biwords >> to refer\n",
      "Correct Biwords >> you can\n",
      "Correct Biwords >> can do\n",
      "Correct Biwords >> do more\n",
      "Correct Biwords >> more example\n",
      "Correct Biwords >> example questions\n",
      "Correct Biwords >> questions within\n",
      "Correct Biwords >> within the\n",
      "Correct Biwords >> the classroom\n",
      "Correct Biwords >> classroom and\n",
      "Correct Biwords >> and it\n",
      "Correct Biwords >> it will\n",
      "Correct Biwords >> will help\n",
      "Correct Biwords >> help us\n",
      "Correct Biwords >> us to\n",
      "Correct Biwords >> to understand\n",
      "Correct Biwords >> understand the\n",
      "Correct Biwords >> the principles\n",
      "Correct Biwords >> principles well\n",
      "Correct Biwords >> Lectures was\n",
      "Correct Biwords >> was well\n",
      "Correct Biwords >> and well\n",
      "Correct Biwords >> well organized\n",
      "Correct Biwords >> It was\n",
      "Correct Biwords >> was easy\n",
      "Correct Biwords >> easy to\n",
      "Correct Biwords >> to understand\n",
      "Correct Biwords >> were also\n",
      "Correct Biwords >> also well\n",
      "Correct Biwords >> well organized\n",
      "Correct Biwords >> Lectures were\n",
      "Correct Biwords >> were good\n",
      "Correct Biwords >> The lecture\n",
      "Correct Biwords >> were well\n",
      "Correct Biwords >> well organized\n",
      "Correct Biwords >> organized and\n",
      "Correct Biwords >> and the\n",
      "Correct Biwords >> the examples\n",
      "Correct Biwords >> examples done\n",
      "Correct Biwords >> done in\n",
      "Correct Biwords >> in the\n",
      "Correct Biwords >> the class\n",
      "Correct Biwords >> class helped\n",
      "Correct Biwords >> helped a\n",
      "Correct Biwords >> a lot\n",
      "Correct Biwords >> lot to\n",
      "Correct Biwords >> to learn\n",
      "Correct Biwords >> learn this\n",
      "Correct Biwords >> this new\n",
      "Correct Biwords >> new language\n",
      "Correct Biwords >> language and\n",
      "Correct Biwords >> and also\n",
      "Correct Biwords >> also the\n",
      "Correct Biwords >> the principles\n",
      "Correct Biwords >> principles of\n",
      "Correct Biwords >> to well\n",
      "Correct Biwords >> Would have\n",
      "Correct Biwords >> have been\n",
      "Correct Biwords >> been better\n",
      "Correct Biwords >> better if\n",
      "Correct Biwords >> if we\n",
      "Correct Biwords >> we discussed\n",
      "Correct Biwords >> discussed more\n",
      "Correct Biwords >> more about\n",
      "Correct Biwords >> about the\n",
      "Correct Biwords >> the solutions\n",
      "Correct Biwords >> solutions of\n",
      "Correct Biwords >> I think\n",
      "Correct Biwords >> think i\n",
      "Correct Biwords >> i learned\n",
      "Correct Biwords >> learned a\n",
      "Correct Biwords >> a lot\n",
      "Correct Biwords >> lot from\n",
      "Correct Biwords >> from the\n",
      "Correct Biwords >> the codes\n",
      "Correct Biwords >> codes you\n",
      "Correct Biwords >> you write\n",
      "Correct Biwords >> write in\n",
      "Correct Biwords >> in the\n",
      "Correct Biwords >> the board\n",
      "Correct Biwords >> When i\n",
      "Correct Biwords >> i compare\n",
      "Correct Biwords >> compare my\n",
      "Correct Biwords >> my codes\n",
      "Correct Biwords >> codes with\n",
      "Correct Biwords >> with yours\n",
      "Correct Biwords >> yours i\n",
      "Correct Biwords >> i can\n",
      "Correct Biwords >> can learn\n",
      "Correct Biwords >> learn about\n",
      "Correct Biwords >> about my\n",
      "Correct Biwords >> my mistakes\n",
      "Correct Biwords >> mistakes and\n",
      "Correct Biwords >> and good\n",
      "Correct Biwords >> practices that\n",
      "Correct Biwords >> that i\n",
      "Correct Biwords >> i should\n",
      "Correct Biwords >> should follow\n",
      "Correct Biwords >> There fore\n",
      "Correct Biwords >> fore i\n",
      "Correct Biwords >> i think\n",
      "Correct Biwords >> think it\n",
      "Correct Biwords >> it would\n",
      "Correct Biwords >> would be\n",
      "Correct Biwords >> be great\n",
      "Correct Biwords >> great if\n",
      "Correct Biwords >> if we\n",
      "Correct Biwords >> we can\n",
      "Correct Biwords >> can discuss\n",
      "Correct Biwords >> discuss more\n",
      "Correct Biwords >> more examples\n",
      "Correct Biwords >> examples in\n",
      "Correct Biwords >> in the\n",
      "Correct Biwords >> the class\n",
      "Correct Biwords >> madam explained\n",
      "Correct Biwords >> explained the\n",
      "Correct Biwords >> concepts clearly\n",
      "Correct Biwords >> clearly with\n",
      "Correct Biwords >> want more\n",
      "Correct Biwords >> more scenario\n",
      "Correct Biwords >> scenario examples\n",
      "Correct Biwords >> examples and\n",
      "Correct Biwords >> and answers\n",
      "Correct Biwords >> answers with\n",
      "Correct Biwords >> with explanations\n",
      "Correct Biwords >> explanations in\n",
      "Correct Biwords >> in future\n",
      "Correct Biwords >> I satisfy\n",
      "Correct Biwords >> satisfy about\n",
      "Correct Biwords >> about first\n",
      "Correct Biwords >> first 7\n",
      "Correct Biwords >> 7 lectures\n",
      "Correct Biwords >> That way\n",
      "Correct Biwords >> way of\n",
      "Correct Biwords >> of teaching\n",
      "Correct Biwords >> teaching is\n",
      "Correct Biwords >> is really\n",
      "Correct Biwords >> really good\n",
      "Correct Biwords >> good for\n",
      "Correct Biwords >> for coming\n",
      "Correct Biwords >> coming lectures\n",
      "Correct Biwords >> lectures too\n",
      "Correct Biwords >> are very\n",
      "Correct Biwords >> very good\n",
      "Correct Biwords >> take good\n",
      "Correct Biwords >> good effort\n",
      "Correct Biwords >> effort to\n",
      "Correct Biwords >> to make\n",
      "Correct Biwords >> every student\n",
      "Correct Biwords >> student in\n",
      "Correct Biwords >> in the\n",
      "Correct Biwords >> the room\n",
      "Correct Biwords >> I was\n",
      "Correct Biwords >> was able\n",
      "Correct Biwords >> able to\n",
      "Correct Biwords >> to obtain\n",
      "Correct Biwords >> obtain a\n",
      "Correct Biwords >> a clear\n",
      "Correct Biwords >> clear picture\n",
      "Correct Biwords >> picture about\n",
      "Correct Biwords >> and its\n",
      "Correct Biwords >> its concepts\n",
      "Correct Biwords >> explanations were\n",
      "Correct Biwords >> were very\n",
      "Correct Biwords >> very clear\n",
      "Correct Biwords >> s very\n",
      "Correct Biwords >> very good\n",
      "Correct Biwords >> good to\n",
      "Correct Biwords >> to letting\n",
      "Correct Biwords >> letting ask\n",
      "Correct Biwords >> ask questions\n",
      "Correct Biwords >> questions and\n",
      "Correct Biwords >> and explain\n",
      "Correct Biwords >> explain again\n",
      "Correct Biwords >> again with\n",
      "Correct Biwords >> with suitable\n",
      "Correct Biwords >> suitable examples\n",
      "Correct Biwords >> some codes\n",
      "Correct Biwords >> codes on\n",
      "Correct Biwords >> on white\n",
      "Correct Biwords >> white board\n",
      "Correct Biwords >> board were\n",
      "Correct Biwords >> were unclear\n",
      "Correct Biwords >> unclear at\n",
      "Correct Biwords >> at the\n",
      "Correct Biwords >> the back\n",
      "Correct Biwords >> overall very\n",
      "Correct Biwords >> very good\n",
      "Correct Biwords >> The lectures\n",
      "Correct Biwords >> lectures were\n",
      "Correct Biwords >> were good\n",
      "Correct Biwords >> good and\n",
      "Correct Biwords >> and clear\n",
      "Correct Biwords >> And they\n",
      "Correct Biwords >> t too\n",
      "Correct Biwords >> too fast\n",
      "Correct Biwords >> Writing code\n",
      "Correct Biwords >> code was\n",
      "Correct Biwords >> was somewhat\n",
      "Correct Biwords >> somewhat confusing\n",
      "Correct Biwords >> confusing because\n",
      "Correct Biwords >> because I\n",
      "Correct Biwords >> t know\n",
      "Correct Biwords >> Actually teaching\n",
      "Correct Biwords >> teaching is\n",
      "Correct Biwords >> is very\n",
      "Correct Biwords >> very good\n",
      "Correct Biwords >> good and\n",
      "Correct Biwords >> and can\n",
      "Correct Biwords >> can understand\n",
      "Correct Biwords >> understand easily\n",
      "Correct Biwords >> easily the\n",
      "Correct Biwords >> the concepts\n",
      "Correct Biwords >> concepts by\n",
      "Correct Biwords >> by examples\n",
      "Correct Biwords >> examples which\n",
      "Correct Biwords >> which are\n",
      "Correct Biwords >> are given\n",
      "Correct Biwords >> given in\n",
      "Correct Biwords >> in the\n",
      "Correct Biwords >> will be\n",
      "Correct Biwords >> be more\n",
      "Correct Biwords >> more helpful\n",
      "Correct Biwords >> helpful if\n",
      "Correct Biwords >> if provide\n",
      "Correct Biwords >> provide solved\n",
      "Correct Biwords >> solved questions\n",
      "Correct Biwords >> questions as\n",
      "Correct Biwords >> as well\n"
     ]
    }
   ],
   "source": [
    "student_con_sens_corr_output_file = open((os.path.join(outputPath,'student_feedback_context_sensitive_corrections.csv')), mode='w+', encoding=\"utf-8\")\n",
    "student_con_sens_corr_output_file.write(\"Incorrect Biword,\" + \"Corrected Result,\" + \"Edit Distance Sum\" + \"\\n\")\n",
    "\n",
    "for index in range(len(student_feedback_tokens) - 1):\n",
    "    biword = student_feedback_tokens[index] + \" \"  + student_feedback_tokens[index+1]\n",
    "    result = sym_spell.word_segmentation(biword)\n",
    "    \n",
    "    if result.corrected_string.lower() != biword.lower():\n",
    "        student_con_sens_corr_output_file.write(biword + \",\" + result.corrected_string + \",\" + str(result.distance_sum) + \"\\n\")\n",
    "    else:\n",
    "        print(\"Correct Biwords >>\", biword)\n",
    "        \n",
    "student_con_sens_corr_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Context sensitive word correction for reseach paper data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Biwords >> network models\n",
      "Correct Biwords >> models have\n",
      "Correct Biwords >> have shown\n",
      "Correct Biwords >> shown their\n",
      "Correct Biwords >> their promising\n",
      "Correct Biwords >> promising opportunities\n",
      "Correct Biwords >> opportunities for\n",
      "Correct Biwords >> which focus\n",
      "Correct Biwords >> focus on\n",
      "Correct Biwords >> on learning\n",
      "Correct Biwords >> learning the\n",
      "Correct Biwords >> the shared\n",
      "Correct Biwords >> shared layers\n",
      "Correct Biwords >> layers to\n",
      "Correct Biwords >> to extract\n",
      "Correct Biwords >> extract the\n",
      "Correct Biwords >> the common\n",
      "Correct Biwords >> common and\n",
      "Correct Biwords >> in most\n",
      "Correct Biwords >> most existing\n",
      "Correct Biwords >> existing approaches\n",
      "Correct Biwords >> the extracted\n",
      "Correct Biwords >> extracted shared\n",
      "Correct Biwords >> shared features\n",
      "Correct Biwords >> features are\n",
      "Correct Biwords >> are prone\n",
      "Correct Biwords >> prone to\n",
      "Correct Biwords >> to be\n",
      "Correct Biwords >> be contaminated\n",
      "Correct Biwords >> contaminated by\n",
      "Correct Biwords >> features or\n",
      "Correct Biwords >> or the\n",
      "Correct Biwords >> the noise\n",
      "Correct Biwords >> noise brought\n",
      "Correct Biwords >> brought by\n",
      "Correct Biwords >> by other\n",
      "Correct Biwords >> other tasks\n",
      "Correct Biwords >> In this\n",
      "Correct Biwords >> this paper\n",
      "Correct Biwords >> we propose\n",
      "Correct Biwords >> propose an\n",
      "Correct Biwords >> learning framework\n",
      "Correct Biwords >> alleviating the\n",
      "Correct Biwords >> the shared\n",
      "Correct Biwords >> shared and\n",
      "Correct Biwords >> and private\n",
      "Correct Biwords >> private latent\n",
      "Correct Biwords >> latent feature\n",
      "Correct Biwords >> feature spaces\n",
      "Correct Biwords >> spaces from\n",
      "Correct Biwords >> from interfering\n",
      "Correct Biwords >> interfering with\n",
      "Correct Biwords >> with each\n",
      "Correct Biwords >> each other\n",
      "Correct Biwords >> We conduct\n",
      "Correct Biwords >> conduct extensive\n",
      "Correct Biwords >> extensive experiments\n",
      "Correct Biwords >> experiments on\n",
      "Correct Biwords >> on 16\n",
      "Correct Biwords >> 16 different\n",
      "Correct Biwords >> different text\n",
      "Correct Biwords >> text classification\n",
      "Correct Biwords >> classification tasks\n",
      "Correct Biwords >> which demonstrates\n",
      "Correct Biwords >> demonstrates the\n",
      "Correct Biwords >> the benefits\n",
      "Correct Biwords >> benefits of\n",
      "Correct Biwords >> of our\n",
      "Correct Biwords >> our approach\n",
      "Correct Biwords >> we show\n",
      "Correct Biwords >> show that\n",
      "Correct Biwords >> that the\n",
      "Correct Biwords >> the shared\n",
      "Correct Biwords >> shared knowledge\n",
      "Correct Biwords >> knowledge learned\n",
      "Correct Biwords >> learned by\n",
      "Correct Biwords >> by our\n",
      "Correct Biwords >> our proposed\n",
      "Correct Biwords >> proposed model\n",
      "Correct Biwords >> model can\n",
      "Correct Biwords >> can be\n",
      "Correct Biwords >> be regarded\n",
      "Correct Biwords >> regarded as\n",
      "Correct Biwords >> knowledge and\n",
      "Correct Biwords >> and easily\n",
      "Correct Biwords >> easily transferred\n",
      "Correct Biwords >> transferred to\n",
      "Correct Biwords >> to new\n",
      "Correct Biwords >> new tasks\n",
      "Correct Biwords >> learning is\n",
      "Correct Biwords >> is an\n",
      "Correct Biwords >> an effective\n",
      "Correct Biwords >> effective approach\n",
      "Correct Biwords >> approach to\n",
      "Correct Biwords >> to improve\n",
      "Correct Biwords >> improve the\n",
      "Correct Biwords >> the performance\n",
      "Correct Biwords >> performance of\n",
      "Correct Biwords >> of a\n",
      "Correct Biwords >> a single\n",
      "Correct Biwords >> single task\n",
      "Correct Biwords >> task with\n",
      "Correct Biwords >> with the\n",
      "Correct Biwords >> the help\n",
      "Correct Biwords >> help of\n",
      "Correct Biwords >> of other\n",
      "Correct Biwords >> other related\n",
      "Correct Biwords >> related tasks\n",
      "Correct Biwords >> models for\n",
      "Correct Biwords >> learning have\n",
      "Correct Biwords >> have become\n",
      "Correct Biwords >> become very\n",
      "Correct Biwords >> very popular\n",
      "Correct Biwords >> ranging from\n",
      "Correct Biwords >> from computer\n",
      "Correct Biwords >> computer vision\n",
      "Correct Biwords >> to natural\n",
      "Correct Biwords >> natural language\n",
      "Correct Biwords >> language processing\n",
      "Correct Biwords >> since they\n",
      "Correct Biwords >> they provide\n",
      "Correct Biwords >> provide a\n",
      "Correct Biwords >> a convenient\n",
      "Correct Biwords >> convenient way\n",
      "Correct Biwords >> way of\n",
      "Correct Biwords >> of combining\n",
      "Correct Biwords >> combining information\n",
      "Correct Biwords >> information from\n",
      "Correct Biwords >> from multiple\n",
      "Correct Biwords >> multiple tasks\n",
      "Correct Biwords >> most existing\n",
      "Correct Biwords >> existing work\n",
      "Correct Biwords >> work on\n",
      "Correct Biwords >> attempts to\n",
      "Correct Biwords >> to divide\n",
      "Correct Biwords >> divide the\n",
      "Correct Biwords >> the features\n",
      "Correct Biwords >> features of\n",
      "Correct Biwords >> of different\n",
      "Correct Biwords >> different tasks\n",
      "Correct Biwords >> tasks into\n",
      "Correct Biwords >> into private\n",
      "Correct Biwords >> private and\n",
      "Correct Biwords >> and shared\n",
      "Correct Biwords >> shared spaces\n",
      "Correct Biwords >> merely based\n",
      "Correct Biwords >> based on\n",
      "Correct Biwords >> on whether\n",
      "Correct Biwords >> of some\n",
      "Correct Biwords >> some components\n",
      "Correct Biwords >> components should\n",
      "Correct Biwords >> should be\n",
      "Correct Biwords >> be shared\n",
      "Correct Biwords >> As shown\n",
      "Correct Biwords >> shown in\n",
      "Correct Biwords >> in Figure\n",
      "Correct Biwords >> the general\n",
      "Correct Biwords >> model introduces\n",
      "Correct Biwords >> introduces two\n",
      "Correct Biwords >> two feature\n",
      "Correct Biwords >> feature spaces\n",
      "Correct Biwords >> spaces for\n",
      "Correct Biwords >> for any\n",
      "Correct Biwords >> any task\n",
      "Correct Biwords >> one is\n",
      "Correct Biwords >> is used\n",
      "Correct Biwords >> used to\n",
      "Correct Biwords >> to store\n",
      "Correct Biwords >> the other\n",
      "Correct Biwords >> other is\n",
      "Correct Biwords >> is used\n",
      "Correct Biwords >> used to\n",
      "Correct Biwords >> to capture\n",
      "Correct Biwords >> capture shared\n",
      "Correct Biwords >> shared features\n",
      "Correct Biwords >> The major\n",
      "Correct Biwords >> major limitation\n",
      "Correct Biwords >> limitation of\n",
      "Correct Biwords >> of this\n",
      "Correct Biwords >> this framework\n",
      "Correct Biwords >> framework is\n",
      "Correct Biwords >> is that\n",
      "Correct Biwords >> that the\n",
      "Correct Biwords >> the shared\n",
      "Correct Biwords >> shared feature\n",
      "Correct Biwords >> feature space\n",
      "Correct Biwords >> space could\n",
      "Correct Biwords >> could contain\n",
      "Correct Biwords >> contain some\n",
      "Correct Biwords >> some unnecessary\n",
      "Correct Biwords >> while some\n",
      "Correct Biwords >> features could\n",
      "Correct Biwords >> could also\n",
      "Correct Biwords >> also be\n",
      "Correct Biwords >> be mixed\n",
      "Correct Biwords >> mixed in\n",
      "Correct Biwords >> in private\n",
      "Correct Biwords >> private space\n",
      "Correct Biwords >> suffering from\n",
      "Correct Biwords >> from feature\n",
      "Correct Biwords >> feature redundancy\n",
      "Correct Biwords >> Taking the\n",
      "Correct Biwords >> the following\n",
      "Correct Biwords >> following two\n",
      "Correct Biwords >> two sentences\n",
      "Correct Biwords >> sentences as\n",
      "Correct Biwords >> as examples\n",
      "Correct Biwords >> which are\n",
      "Correct Biwords >> are extracted\n",
      "Correct Biwords >> extracted from\n",
      "Correct Biwords >> from two\n",
      "Correct Biwords >> two different\n",
      "Correct Biwords >> different sentiment\n",
      "Correct Biwords >> sentiment classification\n",
      "Correct Biwords >> classification tasks\n",
      "Correct Biwords >> Movie reviews\n",
      "Correct Biwords >> reviews and\n",
      "Correct Biwords >> and Baby\n",
      "Correct Biwords >> Baby products\n",
      "Correct Biwords >> products reviews\n",
      "Correct Biwords >> The infantile\n",
      "Correct Biwords >> infantile cart\n",
      "Correct Biwords >> cart is\n",
      "Correct Biwords >> is simple\n",
      "Correct Biwords >> simple and\n",
      "Correct Biwords >> and easy\n",
      "Correct Biwords >> easy to\n",
      "Correct Biwords >> to use\n",
      "Correct Biwords >> This kind\n",
      "Correct Biwords >> kind of\n",
      "Correct Biwords >> of humour\n",
      "Correct Biwords >> humour is\n",
      "Correct Biwords >> is infantile\n",
      "Correct Biwords >> infantile and\n",
      "Correct Biwords >> and boring\n",
      "Correct Biwords >> The word\n",
      "Correct Biwords >> indicates negative\n",
      "Correct Biwords >> negative sentiment\n",
      "Correct Biwords >> sentiment in\n",
      "Correct Biwords >> in Movie\n",
      "Correct Biwords >> Movie task\n",
      "Correct Biwords >> task while\n",
      "Correct Biwords >> while it\n",
      "Correct Biwords >> it is\n",
      "Correct Biwords >> is neutral\n",
      "Correct Biwords >> neutral in\n",
      "Correct Biwords >> in Baby\n",
      "Correct Biwords >> Baby task\n",
      "Correct Biwords >> the general\n",
      "Correct Biwords >> model could\n",
      "Correct Biwords >> could place\n",
      "Correct Biwords >> place the\n",
      "Correct Biwords >> in a\n",
      "Correct Biwords >> a shared\n",
      "Correct Biwords >> shared space\n",
      "Correct Biwords >> leaving potential\n",
      "Correct Biwords >> potential hazards\n",
      "Correct Biwords >> hazards for\n",
      "Correct Biwords >> for other\n",
      "Correct Biwords >> other tasks\n",
      "Correct Biwords >> the capacity\n",
      "Correct Biwords >> capacity of\n",
      "Correct Biwords >> of shared\n",
      "Correct Biwords >> shared space\n",
      "Correct Biwords >> space could\n",
      "Correct Biwords >> could also\n",
      "Correct Biwords >> also be\n",
      "Correct Biwords >> be wasted\n",
      "Correct Biwords >> wasted by\n",
      "Correct Biwords >> by some\n",
      "Correct Biwords >> some unnecessary\n",
      "Correct Biwords >> unnecessary features\n",
      "Correct Biwords >> To address\n",
      "Correct Biwords >> address this\n",
      "Correct Biwords >> this problem\n",
      "Correct Biwords >> in this\n",
      "Correct Biwords >> this paper\n",
      "Correct Biwords >> paper we\n",
      "Correct Biwords >> we propose\n",
      "Correct Biwords >> propose an\n",
      "Correct Biwords >> in which\n",
      "Correct Biwords >> which the\n",
      "Correct Biwords >> the shared\n",
      "Correct Biwords >> shared and\n",
      "Correct Biwords >> and private\n",
      "Correct Biwords >> private feature\n",
      "Correct Biwords >> feature spaces\n",
      "Correct Biwords >> spaces are\n",
      "Correct Biwords >> are in\n",
      "Correct Biwords >> by introducing\n",
      "Correct Biwords >> we design\n",
      "Correct Biwords >> design a\n",
      "Correct Biwords >> shared private\n",
      "Correct Biwords >> private learning\n",
      "Correct Biwords >> learning framework\n",
      "Correct Biwords >> framework to\n",
      "Correct Biwords >> to model\n",
      "Correct Biwords >> model the\n",
      "Correct Biwords >> the text\n",
      "Correct Biwords >> text sequence\n"
     ]
    }
   ],
   "source": [
    "reseachpaper_con_sens_corr_output_file = open((os.path.join(outputPath,'reseachpaper_context_sensitive_corrections.csv')), mode='w+', encoding=\"utf-8\")\n",
    "reseachpaper_con_sens_corr_output_file.write(\"Incorrect Biword,\" + \"Corrected Result,\" + \"Edit Distance Sum\" + \"\\n\")\n",
    "\n",
    "for index in range(len(research_paper_tokens) - 1):\n",
    "    biword = research_paper_tokens[index] + \" \"  + research_paper_tokens[index+1]\n",
    "    result = sym_spell.word_segmentation(biword)\n",
    "    \n",
    "    if result.corrected_string.lower() != biword.lower():\n",
    "        reseachpaper_con_sens_corr_output_file.write(biword + \",\" + result.corrected_string + \",\" + str(result.distance_sum) + \"\\n\")\n",
    "    else:\n",
    "        print(\"Correct Biwords >>\", biword)\n",
    "        \n",
    "reseachpaper_con_sens_corr_output_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming of twitter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_stemmed = [stemmer.stem(token) for token in twitter_tokens]\n",
    "\n",
    "twitter_stemmed_output_file = open((os.path.join(outputPath,\"twitter_stemmed_results.csv\")), mode=\"w+\", encoding=\"Latin-1\")\n",
    "twitter_stemmed_output_file.write(\"Original Token,\" + \"Stemmed Token\\n\")\n",
    "\n",
    "for index in range(len(twitter_stemmed)):\n",
    "    twitter_stemmed_output_file.write(twitter_tokens[index] + \",\" + twitter_stemmed[index] + \"\\n\")\n",
    "    \n",
    "twitter_stemmed_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming of student feedback data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_feedback_stemmed = [stemmer.stem(token) for token in student_feedback_tokens]\n",
    "\n",
    "student_feedback_stemmed_output_file = open((os.path.join(outputPath,\"student_feedback_stemmed_results.csv\")), mode=\"w+\", encoding=\"utf-8\")\n",
    "student_feedback_stemmed_output_file.write(\"Original Token,\" + \"Stemmed Token\\n\")\n",
    "\n",
    "for index in range(len(student_feedback_stemmed)):\n",
    "    student_feedback_stemmed_output_file.write(student_feedback_tokens[index] + \",\" + student_feedback_stemmed[index] + \"\\n\")\n",
    "    \n",
    "student_feedback_stemmed_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming of research paper data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reseachpaper_stemmed = [stemmer.stem(token) for token in research_paper_tokens]\n",
    "\n",
    "reseachpaper_stemmed_output_file = open((os.path.join(outputPath,\"reseachpaper_stemmed_results.csv\")), mode=\"w+\", encoding=\"utf-8\")\n",
    "reseachpaper_stemmed_output_file.write(\"Original Token,\" + \"Stemmed Token\\n\")\n",
    "\n",
    "for index in range(len(reseachpaper_stemmed)):\n",
    "    reseachpaper_stemmed_output_file.write(research_paper_tokens[index] + \",\" + reseachpaper_stemmed[index] + \"\\n\")\n",
    "    \n",
    "reseachpaper_stemmed_output_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\AzeemA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization of twitter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_lemmatized = [wordnet_lemmatizer.lemmatize(word) for word in twitter_tokens]\n",
    "\n",
    "twitter_lemmatized_output_file = open((os.path.join(outputPath,\"twitter_lemmatized_results.csv\")), mode=\"w+\", encoding=\"Latin-1\")\n",
    "twitter_lemmatized_output_file.write(\"Original Token,\" + \"Lemmatized Token\\n\")\n",
    "\n",
    "for index in range(len(twitter_lemmatized)):\n",
    "    twitter_lemmatized_output_file.write(twitter_tokens[index] + \",\" + twitter_lemmatized[index] + \"\\n\")\n",
    "    \n",
    "twitter_lemmatized_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization of student feedback data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_feedback_lemmatized = [wordnet_lemmatizer.lemmatize(word) for word in student_feedback_tokens]\n",
    "\n",
    "student_feedback_lemmatized_output_file = open((os.path.join(outputPath,\"student_feedback_lemmatized_results.csv\")), mode=\"w+\", encoding=\"utf-8\")\n",
    "student_feedback_lemmatized_output_file.write(\"Original Token,\" + \"Lemmatized Token\\n\")\n",
    "\n",
    "for index in range(len(student_feedback_lemmatized)):\n",
    "    student_feedback_lemmatized_output_file.write(student_feedback_tokens[index] + \",\" + student_feedback_lemmatized[index] + \"\\n\")\n",
    "    \n",
    "student_feedback_lemmatized_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization of research paper data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "researchpaper_lemmatized = [wordnet_lemmatizer.lemmatize(word) for word in research_paper_tokens]\n",
    "\n",
    "researchpaper_lemmatized_output_file= open((os.path.join(outputPath,\"researchpaper_lemmatized_results.csv\")), mode=\"w+\", encoding=\"utf-8\")\n",
    "researchpaper_lemmatized_output_file.write(\"Original Token,\" + \"Lemmatized Token\\n\")\n",
    "\n",
    "for index in range(len(researchpaper_lemmatized)):\n",
    "    researchpaper_lemmatized_output_file.write(research_paper_tokens[index] + \",\" + researchpaper_lemmatized[index] + \"\\n\")\n",
    "    \n",
    "researchpaper_lemmatized_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
